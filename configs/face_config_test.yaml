name: "results"
tag: "{${basename:${data.single_view.image_path}}}"
exp_root_dir: "outputs/results_0927/"
seed: 0

data_type: "singleimage-multiview-combined-camera-datamodule"
data:
  prob_multi_view: 0.5
  # for reconstruction
  single_view: # threestudio/data/image.py -> SingleImageDataModuleConfig
    batch_size: [1,1,1]
    height: [128,256,512]
    width: [128,256,512]
    # height: [512,512,512]
    # width: [512,512,512]
    resolution_milestones: [200,300]
    default_elevation_deg: 0
    default_azimuth_deg: 0
    default_camera_distance: 2.0
    default_fovy_deg: 49.1
    image_path: ./load/face/head_rgba.png
    use_random_camera: False
    requires_depth: ${cmaxgt0orcmaxgt0:${system.loss.lambda_depth},${system.loss.lambda_depth_rel}}
    requires_normal: ${cmaxgt0:${system.loss.lambda_normal}}

  # for zero123, video_sd, sd
  multi_view:
    batch_size: [25,25,25] # must be dividable by n_view
    n_view: 25
    width:  [128, 256, 512]
    height: [128, 256, 512]
    resolution_milestones: [200, 300]
    camera_distance_range: [2.0, 2.0]
    fovy_range: [49.1, 49.1] #in degrees
    elevation_range: [0, 0]
    azimuth_range: [0,360]
    camera_perturb: 0.
    center_perturb: 0.
    up_perturb: 0.
    n_val_views: 120
    eval_camera_distance: 2.0
    eval_fovy_deg: 49.1
    relative_radius: false
    eval_height: 512
    eval_width: 512
  
  four_view: # unused
    batch_size: [4, 4, 4] # must be dividable by n_view
    n_view: 4
    width:  [128, 256, 512]
    height: [128, 256, 512]
    resolution_milestones: [200, 300]
    camera_distance_range: [2.0, 2.0]
    fovy_range: [49.1, 49.1] #in degrees
    elevation_range: [0, 0]
    azimuth_range: [-180,180]
    camera_perturb: 0.
    center_perturb: 0.
    up_perturb: 0.
    n_val_views: 120
    eval_camera_distance: 2.0
    eval_fovy_deg: 49.1
    relative_radius: false
    eval_height: 512
    eval_width: 512
  
  front_view: # unused
    batch_size: [1] # must be dividable by n_view
    n_view: 1
    width:  [512]
    height: [512]
    camera_distance_range: [2.0, 2.0]
    fovy_range: [49.1, 49.1] #in degrees
    elevation_range: [0, 0]
    azimuth_range: [-45,45]
    camera_perturb: 0.
    center_perturb: 0.
    up_perturb: 0.
    n_val_views: 120
    eval_camera_distance: 2.0
    eval_fovy_deg: 49.1
    relative_radius: false
    eval_height: 512
    eval_width: 512

system_type: "gsface-system"
system:
  prob_multi_view: ${data.prob_multi_view}
  geometry_type: "gaussian-splatting"
  geometry:
    # geometry_convert_from: "/home/jy496/work/threestudio/custom/threestudio-3dface/results/{head.png}@20240603-192733/ckpts/last.ckpt"
    # position_lr: [0, 0.001, 0.00002, 1000]
    # scale_lr: [0, 0.01, 0.001, 1000]
    position_lr: [0, 0.001, 0.00001, 2000]
    scale_lr: [0, 0.01, 0.005, 2000]
    feature_lr: 0.01
    opacity_lr: 0.05
    rotation_lr: 0.001
    densification_interval: 100
    prune_interval: 100
    opacity_reset_interval: 100000
    densify_from_iter: 0
    densify_until_iter: ${trainer.max_steps}
    prune_from_iter: 0
    prune_until_iter: ${trainer.max_steps}
    densify_grad_threshold: 0.01
    min_opac_prune: 0.005
    split_thresh: 0.02
    radii2d_thresh: 1000
    sphere: False
    init_num_pts: 4096
    pc_init_radius: 0.5
    opacity_init: 0.05
    max_num: 500000

  exporter_type: "gaussian-mesh-exporter"
  renderer_type: "diff-gaussian-rasterizer-advanced"
  renderer:
    debug: false
    invert_bg_prob: 1.0

  material_type: "no-material" # unused
  material:
    n_output_dims: 0

  background_type: "solid-color-background" # unused

  prompt_processor_type: "stable-diffusion-prompt-processor"
  prompt_processor:
    # pretrained_model_name_or_path: "stabilityai/stable-diffusion-2-1-base" 
    pretrained_model_name_or_path: "/home/jy496/work/TeCH/s3/sd_model" # dreambooth
    prompt: ???
    negative_prompt: ???
    front_threshold: 30.
    back_threshold: 30.
    use_perp_neg: False
  
  prompt_processor_type_multi_view: "stable-diffusion-prompt-processor"
  prompt_processor_multi_view:
    spawn: False
    pretrained_model_name_or_path: "stabilityai/stable-diffusion-2-1-base"
    prompt: ???
    negative_prompt: ${system.prompt_processor.negative_prompt}
    front_threshold: 30.
    back_threshold: 30.

  guidance_type: "stable-diffusion-guidance"
  guidance:
    # pretrained_model_name_or_path: "stabilityai/stable-diffusion-2-1-base"
    pretrained_model_name_or_path: "/home/jy496/work/TeCH/s3/sd_model" # dreambooth
    guidance_scale: 100.0
    weighting_strategy: sds
    min_step_percent: 0.02
    max_step_percent: 0.5
    # min_step_percent: 0.02
    # max_step_percent: [50, 0.98, 0.5, 200]



  # #single image sds loss
  # guidance_type: "stable-diffusion-vsd-guidance"
  # guidance:
  #   pretrained_model_name_or_path: "stabilityai/stable-diffusion-2-1-base"
  #   pretrained_model_name_or_path_lora: "stabilityai/stable-diffusion-2-1"
  #   guidance_scale: 7.5 #7.5
  #   # min_step_percent: 0.02
  #   # max_step_percent: 0.5
  #   min_step_percent: [50, 0.02, 0.02, 200]  # (start_iter, start_val, end_val, end_iter)
  #   max_step_percent: [50, 0.98, 0.5, 200]
  
  #face landmark controlnet
  # guidance_type_lmk: "stable-diffusion-controlnet-guidance"
  # guidance_lmk:
  #   pretrained_model_name_or_path: "stabilityai/stable-diffusion-2-1-base"
  #   ddim_scheduler_name_or_path: "stabilityai/stable-diffusion-2-1-base"
  #   control_type: "landmark"
  #   min_step_percent: 0.05
  #   max_step_percent: 0.8
  #   condition_scale: 1.0
  #   fixed_size: 512
  #   use_sds: True

  # guidance_type_lmk: "mp-guidance"
  # guidance_type_srface: "facesr-guidance"
  # guidance_type_srbg: "supir-guidance"

  #mvdream
  guidance_type_multi_view: "mvdream-multiview-diffusion-guidance"
  guidance_multi_view:
    model_name: "sd-v2.1-base-4view"
    ckpt_path: null # path to a pre-downloaded checkpoint file (null for loading from URL)
    guidance_scale: 50.0
    min_step_percent: [0, 0.02, 0.02, 8000]  # (start_iter, start_val, end_val, end_iter)
    max_step_percent: [0, 0.5, 0.5, 8000]
    recon_loss: true
    recon_std_rescale: 0.5

  #zero123
  guidance_type_zero123: "stable-zero123-guidance"
  guidance_zero123:
    pretrained_config: "./load/zero123/sd-objaverse-finetune-c_concat-256.yaml"
    pretrained_model_name_or_path: "./load/zero123/stable_zero123.ckpt"
    vram_O: ${not:${gt0:${system.freq.guidance_eval}}}
    cond_image_path: ${data.single_view.image_path}
    cond_elevation_deg: ${data.single_view.default_elevation_deg}
    cond_azimuth_deg: ${data.single_view.default_azimuth_deg}
    cond_camera_distance: ${data.single_view.default_camera_distance}
    guidance_scale: 3.0
    min_step_percent: [50, 0.7, 0.3, 200]  # (start_iter, start_val, end_val, end_iter)
    max_step_percent: [50, 0.98, 0.8, 200]

  #video
  prompt_processor_type_video: "4dfy-zeroscope-prompt-processor"
  prompt_processor_video:
    pretrained_model_name_or_path: "cerspense/zeroscope_v2_576w"
    prompt: ""
    negative_prompt: ""
    spawn: False

  guidance_type_video: "4dfy-zeroscope-guidance"
  guidance_video:
    pretrained_model_name_or_path: "cerspense/zeroscope_v2_576w"
    guidance_scale: 100. #100
    weighting_strategy: sds
    view_dependent_prompting: False
    min_step_percent: [50, 0.7, 0.3, 200]  # (start_iter, start_val, end_val, end_iter)
    max_step_percent: [50, 0.98, 0.8, 200]
  

  prompt_processor_type_vivid123: "4dfy-zeroscope-prompt-processor"
  prompt_processor_vivid123:
    pretrained_model_name_or_path: "cerspense/zeroscope_v2_576w"
    prompt: ""
    negative_prompt: ""
    spawn: False

  guidance_type_vivid123: "vivid123-guidance"
  guidance_vivid123:
    pretrained_model_name_or_path: "cerspense/zeroscope_v2_576w"
    guidance_scale: 100. #100
    weighting_strategy: sds
    view_dependent_prompting: False
    min_step_percent: [50, 0.7, 0.3, 200]  # (start_iter, start_val, end_val, end_iter)
    max_step_percent: [50, 0.98, 0.8, 200]
    pretrained_config_zero123: "./load/zero123/sd-objaverse-finetune-c_concat-256.yaml"
    pretrained_model_name_or_path_zero123: "./load/zero123/stable_zero123.ckpt"
    vram_O: ${not:${gt0:${system.freq.guidance_eval}}}
    cond_image_path: ${data.single_view.image_path}
    cond_elevation_deg: ${data.single_view.default_elevation_deg}
    cond_azimuth_deg: ${data.single_view.default_azimuth_deg}
    cond_camera_distance: ${data.single_view.default_camera_distance}
    guidance_scale_zero123: 3.0

  guidance_type_lmk: "mp-guidance"
  guidance_lmk:
    sd_version: "2.1"
  
  guidance_type_id: "arcface-guidance"
  guidance_id:
    arcface_path: "/home/jy496/work/arcface/iresnet100/backbone.pth"

  guidance_type_srface: "facesr-guidance"
  guidance_srface:
    face_detector: "/home/jy496/work/CodeFormer/retinaface_resnet50.pth"
    net_sr: "/home/jy496/work/CodeFormer/codeformer_sr.pth"
  # guidance_type_hair: "blip-guidance"
  # hair_prompt: ""

  freq:
    ref_only_steps: 0
    guidance_eval: 0

  loggers:
    wandb:
      enable: false
      project: "threestudio"

  loss:
    lambda_sds: 0.0
    lambda_vsd: 0.0
    lambda_lora: 0.0
    lambda_mvdream: 0.0
    lambda_zero123: 0.1 # 0.1
    lambda_sds_video: 0.01 #0.01 
    lambda_sds_vivid123: 0 
    lambda_mse: 0.0
    lambda_lmk:  0.0
    lambda_sr: 0.0
    lambda_id: 0.0
    # lambda_hair:  0.0
    lambda_cd:  0.0
    lambda_orient: 0.
    lambda_sparsity: 10.
    lambda_opaque: [10000, 0.0, 1000.0, 10001]
    lambda_z_variance: 0.
    lambda_tv: 0.0
    lambda_rgb: [100, 500., 1000., 400]
    lambda_mask: 50.
    lambda_depth: 0. # 0.05
    lambda_depth_rel: 0. # [0, 0, 0.05, 100]
    lambda_normal: 0. # [0, 0, 0.05, 100]
    lambda_normal_smooth: 0.
    lambda_3d_normal_smooth: 0.


  optimizer:
    name: Adam
    args:
      lr: 0.01
      betas: [0.9, 0.99]
      eps: 1.e-8
    params:
      background:
        lr: 0.001

trainer:
  max_steps: 2000
  log_every_n_steps: 1
  num_sanity_val_steps: 0
  val_check_interval: 100
  enable_progress_bar: true
  precision: 32

checkpoint:
  save_last: true
  save_top_k: 0 #-1
  every_n_train_steps: ${trainer.max_steps}
